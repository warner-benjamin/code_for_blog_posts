{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch 1.8 Mish Benchmark V100.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0qkXaxeQJdd",
        "outputId": "226e5716-9581-4a95-d948-090c58092306"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jul 12 16:59:40 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "kwMOphgGqadt",
        "outputId": "9a7c9ae0-dd0d-4cb8-f928-ff9da6616c3c"
      },
      "source": [
        "! pip install torch==1.8.1+cu102 torchvision==0.9.1+cu102 torchaudio===0.8.1 -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/lts/1.8/torch_lts.html\n",
            "Collecting torch==1.8.1+cu102\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/lts/1.8/cu102/torch-1.8.1%2Bcu102-cp37-cp37m-linux_x86_64.whl (804.1MB)\n",
            "\u001b[K     |████████████████████████████████| 804.1MB 23kB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.1+cu102\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/lts/1.8/cu102/torchvision-0.9.1%2Bcu102-cp37-cp37m-linux_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 5.1MB/s \n",
            "\u001b[?25hCollecting torchaudio===0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/55/01ad9244bcd595e39cea5ce30726a7fe02fd963d07daeb136bfe7e23f0a5/torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 15.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu102) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu102) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1+cu102) (7.1.2)\n",
            "\u001b[31mERROR: torchtext 0.10.0 has requirement torch==1.9.0, but you'll have torch 1.8.1+cu102 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "  Found existing installation: torchvision 0.10.0+cu102\n",
            "    Uninstalling torchvision-0.10.0+cu102:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu102\n",
            "Successfully installed torch-1.8.1+cu102 torchaudio-0.8.1 torchvision-0.9.1+cu102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-DLtCXTQSE7",
        "outputId": "44e745c2-c02d-41cb-e534-921a5f7e8251"
      },
      "source": [
        "! pip install fastcore --upgrade -qq\n",
        "! pip install fastai --upgrade -qq\n",
        "! pip install git+https://github.com/thomasbrandon/mish-cuda -qq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 61kB 5.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 194kB 14.6MB/s \n",
            "\u001b[?25h  Building wheel for mish-cuda (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxpd5E0QRCxU"
      },
      "source": [
        "from fastai.vision.all import *\n",
        "import fastai\n",
        "from sys import exit\n",
        "from operator import itemgetter\n",
        "import re\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "import numpy as np\n",
        "from mish_cuda import MishCudaFunction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTtdwOKsQVcS"
      },
      "source": [
        "def scale(val, spec=\"#0.4G\"):\n",
        "    PREFIXES = np.array([c for c in u\"yzafpnµm kMGTPEZY\"])\n",
        "    exp = np.int8(np.log10(np.abs(val)) // 3 * 3 * np.sign(val))\n",
        "    val /= 10.**exp\n",
        "    prefix = PREFIXES[exp//3 + len(PREFIXES)//2]\n",
        "    return f\"{val:{spec}}{prefix}\"\n",
        "\n",
        "def display_times(times):\n",
        "    return f\"{scale(times.mean())}s ± {scale(times.std())}s, {scale(times.min())}s, {scale(times.max())}s\"\n",
        "\n",
        "def profile_cuda(func, inp, n_repeat=100, warmup=10):\n",
        "    fwd_times,bwd_times = [],[]\n",
        "    for i in range(n_repeat + warmup):\n",
        "        start,end = (torch.cuda.Event(enable_timing=True) for _ in range(2))\n",
        "        start.record()\n",
        "        res = func(inp)\n",
        "        end.record()\n",
        "        torch.cuda.synchronize()\n",
        "        if i >= warmup: fwd_times.append(start.elapsed_time(end))\n",
        "        start,end = (torch.cuda.Event(enable_timing=True) for _ in range(2))\n",
        "        inp = inp.clone().requires_grad_()\n",
        "        y = func(inp)\n",
        "        l = y.mean()\n",
        "        start.record()\n",
        "        _ = torch.autograd.grad(l, inp)\n",
        "        end.record()\n",
        "        torch.cuda.synchronize()\n",
        "        if i >= warmup: bwd_times.append(start.elapsed_time(end))\n",
        "    return (np.array(fwd_times)/1000, # Elapsed time is in ms\n",
        "            np.array(bwd_times)/1000)\n",
        "\n",
        "mish_pt = lambda x: x.mul(torch.tanh(F.softplus(x)))\n",
        "\n",
        "def profile(device='cuda', n_repeat=100, warmup=10, size='(16,10,256,256)', baseline=True, types='all'):\n",
        "    if types == 'all': \n",
        "        dtypes = [torch.float16, torch.bfloat16, torch.float32, torch.float64]\n",
        "    else:\n",
        "        if not hasattr(torch, types): exit(\"Invalid data type, expected torch type or 'all', got {types}\")\n",
        "        dtypes = [getattr(torch, types)]\n",
        "    dev = torch.device(type=device)\n",
        "    sz_str = size.replace(' ','')\n",
        "    if not re.match(r\"[\\(\\[]\\d+(,\\d+)*[\\)\\]]\", sz_str):\n",
        "        exit(\"Badly formatted size, should be a list or tuple such as \\\"(1,2,3)\\\".\")\n",
        "    sz = list(map(int, sz_str[1:-1].split(',')))\n",
        "    print(f\"Profiling over {n_repeat} runs after {warmup} warmup runs.\")\n",
        "    for dtype in dtypes:\n",
        "        if len(dtypes) > 1:\n",
        "            print(f\"Testing on {dtype}:\")\n",
        "            ind = ' '\n",
        "        else: ind = ''\n",
        "        inp = torch.randn(*sz, dtype=dtype, device=dev)\n",
        "        timings = []\n",
        "        funcs = {}\n",
        "        funcs.update(relu = torch.nn.functional.relu, \n",
        "                     leaky_relu = torch.nn.functional.leaky_relu,\n",
        "                     softplus = torch.nn.functional.softplus,\n",
        "                     silu_jit = fastai.layers.swish,\n",
        "                     silu_native = torch.nn.functional.silu,\n",
        "                     mish_naive = mish_pt,\n",
        "                     mish_jit = fastai.layers.mish,\n",
        "                     mish_cuda = MishCudaFunction.apply)\n",
        "        if device=='cpu': funcs.pop('mish_cuda')\n",
        "        max_name = max(map(len, funcs.keys())) + 6\n",
        "        for (name,func) in funcs.items():\n",
        "            if device=='cuda':\n",
        "                if (name=='mish_cuda') and (dtype==torch.bfloat16):\n",
        "                    pass\n",
        "                else: fwd_times,bwd_times = profile_cuda(func, inp, n_repeat, warmup)\n",
        "            print(ind+(name+'_fwd:').ljust(max_name) + display_times(fwd_times))\n",
        "            print(ind+(name+'_bwd:').ljust(max_name) + display_times(bwd_times))\n",
        "            torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioZYwlx1S_qH",
        "outputId": "31230d49-765e-4bc0-f535-397968b822e0"
      },
      "source": [
        "profile('cuda')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Profiling over 100 runs after 10 warmup runs.\n",
            "Testing on torch.float16:\n",
            " relu_fwd:        96.16µs ± 2.513µs, 94.21µs, 107.5µs\n",
            " relu_bwd:        174.2µs ± 10.19µs, 159.7µs, 217.1µs\n",
            " leaky_relu_fwd:  99.91µs ± 23.17µs, 88.06µs, 293.9µs\n",
            " leaky_relu_bwd:  248.1µs ± 421.7µs, 155.6µs, 3.763ms\n",
            " softplus_fwd:    99.59µs ± 3.792µs, 96.26µs, 120.8µs\n",
            " softplus_bwd:    192.7µs ± 179.1µs, 158.7µs, 1.964ms\n",
            " silu_jit_fwd:    110.8µs ± 4.060µs, 106.5µs, 126.0µs\n",
            " silu_jit_bwd:    208.9µs ± 21.59µs, 186.4µs, 347.1µs\n",
            " silu_native_fwd: 94.23µs ± 4.252µs, 91.14µs, 111.6µs\n",
            " silu_native_bwd: 173.7µs ± 21.12µs, 154.6µs, 303.1µs\n",
            " mish_naive_fwd:  241.1µs ± 5.324µs, 235.5µs, 267.3µs\n",
            " mish_naive_bwd:  504.7µs ± 359.3µs, 463.9µs, 4.080ms\n",
            " mish_jit_fwd:    195.0µs ± 6.865µs, 189.4µs, 244.7µs\n",
            " mish_jit_bwd:    261.5µs ± 9.261µs, 254.0µs, 294.9µs\n",
            " mish_cuda_fwd:   118.8µs ± 4.640µs, 115.7µs, 149.5µs\n",
            " mish_cuda_bwd:   205.0µs ± 75.83µs, 173.1µs, 840.7µs\n",
            "Testing on torch.bfloat16:\n",
            " relu_fwd:        85.61µs ± 3.666µs, 83.97µs, 102.4µs\n",
            " relu_bwd:        171.5µs ± 13.31µs, 149.5µs, 206.8µs\n",
            " leaky_relu_fwd:  91.97µs ± 66.68µs, 79.87µs, 754.7µs\n",
            " leaky_relu_bwd:  209.2µs ± 268.3µs, 151.6µs, 2.597ms\n",
            " softplus_fwd:    99.76µs ± 1.696µs, 98.30µs, 106.5µs\n",
            " softplus_bwd:    159.5µs ± 16.70µs, 146.4µs, 275.5µs\n",
            " silu_jit_fwd:    182.8µs ± 5.078µs, 177.2µs, 205.8µs\n",
            " silu_jit_bwd:    568.9µs ± 122.0µs, 541.7µs, 1.560ms\n",
            " silu_native_fwd: 88.71µs ± 2.927µs, 86.02µs, 103.4µs\n",
            " silu_native_bwd: 171.5µs ± 13.83µs, 147.5µs, 228.4µs\n",
            " mish_naive_fwd:  243.1µs ± 4.139µs, 239.6µs, 260.1µs\n",
            " mish_naive_bwd:  482.6µs ± 177.1µs, 458.8µs, 2.214ms\n",
            " mish_jit_fwd:    259.7µs ± 33.09µs, 252.9µs, 584.7µs\n",
            " mish_jit_bwd:    781.3µs ± 191.0µs, 759.8µs, 2.681ms\n",
            " mish_cuda_fwd:   259.7µs ± 33.09µs, 252.9µs, 584.7µs\n",
            " mish_cuda_bwd:   781.3µs ± 191.0µs, 759.8µs, 2.681ms\n",
            "Testing on torch.float32:\n",
            " relu_fwd:        129.4µs ± 3.984µs, 126.0µs, 146.4µs\n",
            " relu_bwd:        220.9µs ± 25.02µs, 216.1µs, 448.5µs\n",
            " leaky_relu_fwd:  130.7µs ± 4.009µs, 128.0µs, 148.5µs\n",
            " leaky_relu_bwd:  234.1µs ± 158.8µs, 216.1µs, 1.812ms\n",
            " softplus_fwd:    138.5µs ± 78.90µs, 128.0µs, 922.6µs\n",
            " softplus_bwd:    238.2µs ± 197.8µs, 217.1µs, 2.207ms\n",
            " silu_jit_fwd:    299.8µs ± 7.123µs, 294.9µs, 341.0µs\n",
            " silu_jit_bwd:    958.0µs ± 127.0µs, 932.9µs, 1.993ms\n",
            " silu_native_fwd: 133.1µs ± 3.747µs, 124.9µs, 146.4µs\n",
            " silu_native_bwd: 217.9µs ± 1.215µs, 217.1µs, 228.4µs\n",
            " mish_naive_fwd:  398.7µs ± 55.39µs, 386.0µs, 938.0µs\n",
            " mish_naive_bwd:  856.2µs ± 243.4µs, 819.2µs, 2.613ms\n",
            " mish_jit_fwd:    407.7µs ± 28.66µs, 399.4µs, 641.0µs\n",
            " mish_jit_bwd:    1.323ms ± 184.6µs, 1.295ms, 3.063ms\n",
            " mish_cuda_fwd:   142.3µs ± 5.070µs, 138.2µs, 164.9µs\n",
            " mish_cuda_bwd:   281.1µs ± 557.4µs, 222.2µs, 5.826ms\n",
            "Testing on torch.float64:\n",
            " relu_fwd:        326.7µs ± 28.28µs, 315.4µs, 566.3µs\n",
            " relu_bwd:        497.3µs ± 189.2µs, 470.0µs, 2.343ms\n",
            " leaky_relu_fwd:  321.8µs ± 6.283µs, 315.4µs, 349.2µs\n",
            " leaky_relu_bwd:  472.0µs ± 1.451µs, 469.0µs, 479.2µs\n",
            " softplus_fwd:    316.9µs ± 4.720µs, 310.3µs, 335.9µs\n",
            " softplus_bwd:    469.5µs ± 1.753µs, 466.9µs, 478.2µs\n",
            " silu_jit_fwd:    727.0µs ± 10.50µs, 715.8µs, 786.4µs\n",
            " silu_jit_bwd:    2.481ms ± 302.3µs, 2.412ms, 4.910ms\n",
            " silu_native_fwd: 322.0µs ± 15.89µs, 316.4µs, 475.1µs\n",
            " silu_native_bwd: 472.8µs ± 1.526µs, 469.0µs, 477.2µs\n",
            " mish_naive_fwd:  997.1µs ± 18.65µs, 987.1µs, 1.176ms\n",
            " mish_naive_bwd:  1.990ms ± 3.833µs, 1.983ms, 2.002ms\n",
            " mish_jit_fwd:    1.010ms ± 7.377µs, 1.000ms, 1.036ms\n",
            " mish_jit_bwd:    3.421ms ± 229.3µs, 3.378ms, 5.051ms\n",
            " mish_cuda_fwd:   346.5µs ± 4.061µs, 343.0µs, 366.6µs\n",
            " mish_cuda_bwd:   471.2µs ± 827.5ns, 470.0µs, 473.1µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tswXMRr7gXZg",
        "outputId": "41997c4e-56cc-4c1f-964d-521d774a570c"
      },
      "source": [
        "profile('cuda', size='(64,10,256,256)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Profiling over 100 runs after 10 warmup runs.\n",
            "Testing on torch.float16:\n",
            " relu_fwd:        261.8µs ± 3.682µs, 258.0µs, 280.6µs\n",
            " relu_bwd:        540.9µs ± 707.3ns, 539.6µs, 542.7µs\n",
            " leaky_relu_fwd:  264.8µs ± 9.853µs, 259.1µs, 322.6µs\n",
            " leaky_relu_bwd:  584.7µs ± 226.3µs, 539.6µs, 2.373ms\n",
            " softplus_fwd:    301.7µs ± 8.958µs, 293.9µs, 343.0µs\n",
            " softplus_bwd:    583.2µs ± 173.1µs, 547.8µs, 2.006ms\n",
            " silu_jit_fwd:    585.6µs ± 7.832µs, 577.5µs, 624.6µs\n",
            " silu_jit_bwd:    2.127ms ± 304.0µs, 2.079ms, 4.933ms\n",
            " silu_native_fwd: 264.4µs ± 3.303µs, 261.1µs, 278.5µs\n",
            " silu_native_bwd: 543.1µs ± 955.3ns, 541.7µs, 549.9µs\n",
            " mish_naive_fwd:  839.8µs ± 12.17µs, 832.5µs, 949.2µs\n",
            " mish_naive_bwd:  1.756ms ± 20.98µs, 1.751ms, 1.964ms\n",
            " mish_jit_fwd:    852.6µs ± 7.428µs, 844.8µs, 892.9µs\n",
            " mish_jit_bwd:    2.904ms ± 145.6µs, 2.887ms, 4.352ms\n",
            " mish_cuda_fwd:   371.7µs ± 3.792µs, 368.6µs, 389.1µs\n",
            " mish_cuda_bwd:   647.7µs ± 3.224µs, 644.1µs, 655.4µs\n",
            "Testing on torch.bfloat16:\n",
            " relu_fwd:        265.0µs ± 31.70µs, 258.0µs, 577.5µs\n",
            " relu_bwd:        541.2µs ± 1.521µs, 539.6µs, 554.0µs\n",
            " leaky_relu_fwd:  263.2µs ± 6.461µs, 251.9µs, 294.9µs\n",
            " leaky_relu_bwd:  581.6µs ± 248.5µs, 540.7µs, 2.741ms\n",
            " softplus_fwd:    325.3µs ± 6.438µs, 319.5µs, 351.2µs\n",
            " softplus_bwd:    573.7µs ± 213.7µs, 548.9µs, 2.700ms\n",
            " silu_jit_fwd:    581.3µs ± 6.284µs, 576.5µs, 625.7µs\n",
            " silu_jit_bwd:    2.088ms ± 48.47µs, 2.080ms, 2.558ms\n",
            " silu_native_fwd: 267.0µs ± 5.466µs, 262.1µs, 282.6µs\n",
            " silu_native_bwd: 566.7µs ± 178.8µs, 542.7µs, 2.273ms\n",
            " mish_naive_fwd:  862.3µs ± 5.889µs, 857.1µs, 889.9µs\n",
            " mish_naive_bwd:  1.756ms ± 2.309µs, 1.751ms, 1.760ms\n",
            " mish_jit_fwd:    877.0µs ± 7.376µs, 870.4µs, 913.4µs\n",
            " mish_jit_bwd:    2.956ms ± 283.9µs, 2.913ms, 5.157ms\n",
            " mish_cuda_fwd:   877.0µs ± 7.376µs, 870.4µs, 913.4µs\n",
            " mish_cuda_bwd:   2.956ms ± 283.9µs, 2.913ms, 5.157ms\n",
            "Testing on torch.float32:\n",
            " relu_fwd:        439.2µs ± 20.29µs, 432.1µs, 633.9µs\n",
            " relu_bwd:        850.2µs ± 159.0µs, 832.5µs, 2.432ms\n",
            " leaky_relu_fwd:  442.2µs ± 25.99µs, 433.2µs, 692.2µs\n",
            " leaky_relu_bwd:  858.5µs ± 236.3µs, 832.5µs, 3.208ms\n",
            " softplus_fwd:    441.3µs ± 19.38µs, 434.2µs, 620.5µs\n",
            " softplus_bwd:    853.0µs ± 177.3µs, 833.5µs, 2.617ms\n",
            " silu_jit_fwd:    1.052ms ± 9.021µs, 1.043ms, 1.090ms\n",
            " silu_jit_bwd:    3.665ms ± 92.40µs, 3.654ms, 4.584ms\n",
            " silu_native_fwd: 440.8µs ± 5.310µs, 437.2µs, 471.0µs\n",
            " silu_native_bwd: 875.0µs ± 392.0µs, 833.5µs, 4.774ms\n",
            " mish_naive_fwd:  1.450ms ± 25.78µs, 1.436ms, 1.696ms\n",
            " mish_naive_bwd:  3.210ms ± 2.759µs, 3.207ms, 3.235ms\n",
            " mish_jit_fwd:    1.462ms ± 7.694µs, 1.452ms, 1.495ms\n",
            " mish_jit_bwd:    5.094ms ± 235.2µs, 5.068ms, 7.434ms\n",
            " mish_cuda_fwd:   470.9µs ± 5.393µs, 457.7µs, 490.5µs\n",
            " mish_cuda_bwd:   890.4µs ± 241.9µs, 854.0µs, 3.169ms\n",
            "Testing on torch.float64:\n",
            " relu_fwd:        1.196ms ± 6.100µs, 1.187ms, 1.213ms\n",
            " relu_bwd:        1.862ms ± 2.412µs, 1.858ms, 1.873ms\n",
            " leaky_relu_fwd:  1.198ms ± 6.540µs, 1.190ms, 1.224ms\n",
            " leaky_relu_bwd:  1.860ms ± 1.987µs, 1.853ms, 1.865ms\n",
            " softplus_fwd:    1.174ms ± 6.420µs, 1.163ms, 1.200ms\n",
            " softplus_bwd:    1.851ms ± 52.03µs, 1.841ms, 2.369ms\n",
            " silu_jit_fwd:    2.746ms ± 7.467µs, 2.729ms, 2.769ms\n",
            " silu_jit_bwd:    9.614ms ± 6.963µs, 9.600ms, 9.639ms\n",
            " silu_native_fwd: 1.198ms ± 45.19µs, 1.184ms, 1.634ms\n",
            " silu_native_bwd: 1.879ms ± 184.3µs, 1.857ms, 3.713ms\n",
            " mish_naive_fwd:  3.859ms ± 6.589µs, 3.847ms, 3.881ms\n",
            " mish_naive_bwd:  7.881ms ± 6.417µs, 7.864ms, 7.895ms\n",
            " mish_jit_fwd:    3.879ms ± 9.492µs, 3.859ms, 3.901ms\n",
            " mish_jit_bwd:    13.43ms ± 9.226µs, 13.41ms, 13.45ms\n",
            " mish_cuda_fwd:   1.274ms ± 4.645µs, 1.269ms, 1.290ms\n",
            " mish_cuda_bwd:   1.855ms ± 69.55µs, 1.845ms, 2.545ms\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}